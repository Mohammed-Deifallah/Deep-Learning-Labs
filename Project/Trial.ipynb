{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import listdir\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pickle import dump, load\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split a document into news story and highlights\n",
    "def split_story(doc):\n",
    "\t# find first highlight\n",
    "\tindex = doc.find('@highlight')\n",
    "\t# split into story and highlights\n",
    "\tstory, highlights = doc[:index], doc[index:].split('@highlight')\n",
    "\t# strip extra white space around each highlight\n",
    "\thighlights = [h.strip() for h in highlights if len(h) > 0]\n",
    "\treturn story, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all stories in a directory\n",
    "def load_stories(directory):\n",
    "\tall_stories = list()\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\t# load document\n",
    "\t\tdoc = load_doc(filename)\n",
    "\t\t# split into story and highlights\n",
    "\t\tstory, highlights = split_story(doc)\n",
    "\t\t# store\n",
    "\t\tall_stories.append({'story':story, 'highlights':highlights})\n",
    "\treturn all_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "                                          highlights  \\\n",
      "0  [The 15 new cardinals will be installed on Feb...   \n",
      "1  [NEW: Bermudan premier: \"Above all, this was a...   \n",
      "2  [A 4-year-old boy is the latest victim of a ma...   \n",
      "3  [NEW: Kyle White: \"Without this team, there wo...   \n",
      "4  [Captive boys and men were rescued from an Isl...   \n",
      "\n",
      "                                               story  \n",
      "0  (CNN)For the second time during his papacy, Po...  \n",
      "1  HAMILTON, Bermuda (CNN) -- Four Chinese nation...  \n",
      "2  Kathmandu, Nepal (CNN) -- A ferocious leopard ...  \n",
      "3  (CNN) -- Kyle White now has two pieces of meta...  \n",
      "4  (CNN) -- The 54 men and 14 boys rescued after ...  \n",
      "highlights    0\n",
      "story         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.DataFrame.from_dict(load_stories('../../ProjectDataset/cnn/examples/'))\n",
    "\n",
    "print(reviews.shape)\n",
    "\n",
    "print(reviews.head())\n",
    "\n",
    "print(reviews.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The 15 new cardinals will be installed on Feb...</td>\n",
       "      <td>(CNN)For the second time during his papacy, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[NEW: Bermudan premier: \"Above all, this was a...</td>\n",
       "      <td>HAMILTON, Bermuda (CNN) -- Four Chinese nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A 4-year-old boy is the latest victim of a ma...</td>\n",
       "      <td>Kathmandu, Nepal (CNN) -- A ferocious leopard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[NEW: Kyle White: \"Without this team, there wo...</td>\n",
       "      <td>(CNN) -- Kyle White now has two pieces of meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Captive boys and men were rescued from an Isl...</td>\n",
       "      <td>(CNN) -- The 54 men and 14 boys rescued after ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  \\\n",
       "0  [The 15 new cardinals will be installed on Feb...   \n",
       "1  [NEW: Bermudan premier: \"Above all, this was a...   \n",
       "2  [A 4-year-old boy is the latest victim of a ma...   \n",
       "3  [NEW: Kyle White: \"Without this team, there wo...   \n",
       "4  [Captive boys and men were rescued from an Isl...   \n",
       "\n",
       "                                               story  \n",
       "0  (CNN)For the second time during his papacy, Po...  \n",
       "1  HAMILTON, Bermuda (CNN) -- Four Chinese nation...  \n",
       "2  Kathmandu, Nepal (CNN) -- A ferocious leopard ...  \n",
       "3  (CNN) -- Kyle White now has two pieces of meta...  \n",
       "4  (CNN) -- The 54 men and 14 boys rescued after ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The 15 new cardinals will be installed on Feb...</td>\n",
       "      <td>(CNN)For the second time during his papacy, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[NEW: Bermudan premier: \"Above all, this was a...</td>\n",
       "      <td>HAMILTON, Bermuda (CNN) -- Four Chinese nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A 4-year-old boy is the latest victim of a ma...</td>\n",
       "      <td>Kathmandu, Nepal (CNN) -- A ferocious leopard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[NEW: Kyle White: \"Without this team, there wo...</td>\n",
       "      <td>(CNN) -- Kyle White now has two pieces of meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Captive boys and men were rescued from an Isl...</td>\n",
       "      <td>(CNN) -- The 54 men and 14 boys rescued after ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  \\\n",
       "0  [The 15 new cardinals will be installed on Feb...   \n",
       "1  [NEW: Bermudan premier: \"Above all, this was a...   \n",
       "2  [A 4-year-old boy is the latest victim of a ma...   \n",
       "3  [NEW: Kyle White: \"Without this team, there wo...   \n",
       "4  [Captive boys and men were rescued from an Isl...   \n",
       "\n",
       "                                               story  \n",
       "0  (CNN)For the second time during his papacy, Po...  \n",
       "1  HAMILTON, Bermuda (CNN) -- Four Chinese nation...  \n",
       "2  Kathmandu, Nepal (CNN) -- A ferocious leopard ...  \n",
       "3  (CNN) -- Kyle White now has two pieces of meta...  \n",
       "4  (CNN) -- The 54 men and 14 boys rescued after ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(CNN)For the second time during his papacy, Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.\\n\\nPope Francis said Sunday that he would hold a meeting of cardinals on February 14 \"during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world,\" according to Vatican Radio.\\n\\nNew cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church.\\n\\nThe new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.\\n\\n\"This is a pope who very much wants to reach out to people on the margins, and you clearly see that in this set,\" Allen said. \"You\\'re talking about cardinals from typically overlooked places, like Cape Verde, the Pacific island of Tonga, Panama, Thailand, Uruguay.\"\\n\\nBut for the second time since Francis\\' election, no Americans made the list.\\n\\n\"Francis\\' pattern is very clear: He wants to go to the geographical peripheries rather than places that are already top-heavy with cardinals,\" Allen said.\\n\\nChristopher Bellitto, a professor of church history at Kean University in New Jersey, noted that Francis announced his new slate of cardinals on the Catholic Feast of the Epiphany, which commemorates the visit of the Magi to Jesus\\' birthplace in Bethlehem.\\n\\n\"On feast of three wise men from far away, the Pope\\'s choices for cardinal say that every local church deserves a place at the big table.\"\\n\\nIn other words, Francis wants a more decentralized church and wants to hear reform ideas from small communities that sit far from Catholicism\\'s power centers, Bellitto said.\\n\\nThat doesn\\'t mean Francis is the first pontiff to appoint cardinals from the developing world, though. Beginning in the 1920s, an increasing number of Latin American churchmen were named cardinals, and in the 1960s, St. John XXIII, whom Francis canonized last year, appointed the first cardinals from Japan, the Philippines and Africa.\\n\\nIn addition to the 15 new cardinals Francis named on Sunday, five retired archbishops and bishops will also be honored as cardinals.\\n\\nLast year, Pope Francis appointed 19 new cardinals, including bishops from Haiti and Burkina Faso.\\n\\nCNN\\'s Daniel Burke and Christabelle Fombu contributed to this report.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['The 15 new cardinals will be installed on February 14',\n",
       " 'They come from countries such as Myanmar and Tonga',\n",
       " \"No Americans made the list this time or the previous time in Francis' papacy\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HAMILTON, Bermuda (CNN) -- Four Chinese nationals of Uyghur ethnicity who had been held at the U.S. military\\'s Guantanamo Bay, Cuba, detention facility have been resettled in Bermuda, officials said Thursday.\\n\\nAttorney General Eric Holder says the U.S. is \"extremely grateful to the government of Bermuda.\"\\n\\n\"Above all, this was a humanitarian act,\" Bermudan Premier Ewart Brown told CNN in an interview at his Cabinet office in Hamilton, Bermuda. \"We don\\'t see it as quid pro quo.\"\\n\\nThe four were twice cleared for release -- once by the Bush administration and again this year, according to a Justice Department statement.\\n\\nThey were among 17 Uyghur detainees at the facility set up to hold terror suspects.\\n\\nThe four were flown by private plane Wednesday night from Cuba to Bermuda and were accompanied by U.S. and Bermudan representatives as well as their attorneys, according to Susan Baker Manning, part of the men\\'s legal team.\\n\\nPresident Obama has pledged to close the Guantanamo facility, raising questions of what will happen to the more than 200 remaining detainees. A political backlash against bringing any of the detainees to the United States has increased the focus on sending them to other countries.\\n\\nBrown said he read an article on the issue of the Guantanamo Bay detainees\\' fates in The Washington Post while he was in Washington for a White House meeting in May. He said he decided to put an offer to the U.S. government \"on the table.\"\\n\\nHe said Bermuda, a British colony, told London of its intentions, but not until late in the process. Britain must approve the transfer for it to be permanent, Brown said, adding that he believes the issue may raise tension between Bermuda and Britain.\\n\\nThe issue is controversial because of China\\'s opposition to the Uyghurs being sent to any country but China.\\n\\nUyghurs are a Muslim minority from the Xinjiang province of far-west China. The 17 Uyghurs had left China and made their way to Afghanistan, where they settled in a camp with other Uyghurs opposed to the Chinese government, the Justice Department said in its statement.\\n\\nThey left Afghanistan after U.S. bombings began in the area in October 2001 and were apprehended in Pakistan, the statement said.  Watch concerns about resettling the Uyghur detainees »\\n\\n\"According to available information, these individuals did not travel to Afghanistan with the intent to take any hostile action against the United States,\" the statement said.\\n\\nManning said the 17 were picked up as a matter of circumstance and never had terrorist training.\\n\\nThey left China because they did not agree with the government, she told CNN.\\n\\nHowever, China alleges the men are part of the East Turkestan Islamic Movement -- a group the U.S. State Department considers a terrorist organization -- that operates in the Xinjiang region. East Turkestan is another name for Xinjiang.\\n\\nChina on Thursday urged the United States to hand over all 17 of the Uyghurs instead of sending them elsewhere. The Chinese statement followed an offer by Palau, a Pacific island nation, to accept the Uyghur detainees.\\n\\nThe Xinjiang region of 20 million people is largely populated by ethnic Uyghurs and other Muslim minorities who have traditionally opposed Beijing\\'s rule and clamored for greater autonomy.\\n\\nA senior U.S. administration official told CNN the State Department is working on a final agreement with Palau to settle the matter of the 13 remaining Uyghur detainees.\\n\\nIssues to be worked out include how to transfer the Uyghurs to Palau and how much money the United States would give the men for resettlement, the official said.\\n\\nThe official said the average in such cases is $100,000 per person.\\n\\nThe United States will not send Uyghur detainees cleared for release back to China out of concern that they would be tortured by Chinese authorities. China has said no returned Uyghurs would be tortured.\\n\\nPalau said it will take in the ethnic Uyghur detainees for humanitarian reasons and because of the \"special relationship\" between Palau and the United States.\\n\\nPalau, with a population of about 20,000, is about 1,000 miles (1,600 kilometers) southeast of Manila in the Philippines and about 4,600 miles (7,400 kilometers) west of Hawaii. It has received nearly $900 million in U.S. aid since independence in 1994, according to congressional auditors, and depends on Washington for its defense.\\n\\nIn 2006, five other Uyghur detainees were transferred to Albania, according to the Justice Department, which said it has no reports they took part in any post-resettlement criminal behavior or terrorist activities.\\n\\nSince 2002, more than 540 detainees have departed Guantanamo for other countries, including Albania, Algeria, Afghanistan, Australia, Bangladesh, Bahrain, Belgium, Denmark, Egypt, France, Great Britain, Iran, Iraq, Jordan, Kazakhstan, Kuwait, Libya, Maldives, Mauritania, Morocco, Pakistan, Russia, Saudi Arabia, Spain, Sweden, Sudan, Tajikistan, Turkey, Uganda, the United Kingdom and Yemen, the Justice Department said.\\n\\nCNN\\'s Brian Vitagliano and Don Lemon contributed to this report.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['NEW: Bermudan premier: \"Above all, this was a humanitarian act\"',\n",
       " 'Uyghurs are native Chinese Muslims; the detainees were apprehended in Pakistan',\n",
       " 'China urges U.S. to hand over all 17 Uyghurs held at Guantanamo Bay, Cuba',\n",
       " 'Official says U.S. still negotiating with Palau to take remaining 13 Uyghurs']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kathmandu, Nepal (CNN) -- A ferocious leopard may have killed 15 people in Nepal in a 15-month span, its latest victim a 4-year-old boy that the creature dragged away into the jungle to eat.\\n\\nThe head of boy was found in the forest a kilometer from his home Saturday morning, said Kamal Prasad Kharel, the police chief of the Baitadi district, an area about 600 kilometers (373 miles) west of Kathmandu.\\n\\nThe grisly discovery, which came after teams of people searched for the child, marks the 15th victim in the past 15 months in that remote district in western Nepal.\\n\\nThe police chief suspects that a single man-eating leopard is responsible for the deaths. If not, there are at most two of the man-eating creatures around, he believes.\\n\\nMaheshwor Dhakal, an ecologist at the Department of National Parks and Wildlife Conservation in Kathmandu, agreed that it is unusual to find more than one or two man-eating animals in one area. Most leopards live on wild prey.\\n\\nMore human victims could also be expected if there were more than one or two man-eaters around, he said.\\n\\n\"Since human blood has more salt than animal blood, once wild animals get the taste of salty blood they do not like other animals like deer,\" Dhakal said.\\n\\nKharel said he feared the actual number of people killed by the leopard could be higher than 15, because others have lost their life to leopard attacks in Uttarkhand state in northern India, which borders Baitadi district.\\n\\n\"It could be the same leopard,\" he said.\\n\\nOf the 15 victims in Nepal so far, two-thirds are children below the age of 10. The others are older children and a 29-year-old woman who had gone to collect fodder for domestic animals in the nearby forest, a common practice in Nepal.\\n\\n\"No adult male has been killed,\" Kharel said.\\n\\nAll the victims are from villages bordering the dense forests in the district, he said.\\n\\nAfter killing its victim, the leopard takes the body away into the forest to eat.\\n\\n\"In the case of the children it just leaves behind the head, eating everything, but some parts of the adult body are left behind because it cannot finish it,\" Kharel added.\\n\\nThe district administration has announced a Rs. 25,000 (about $300) reward to anyone who captures or kills the leopard.\\n\\nThe local administration has sought to raise public awareness of the dangers of going alone into nearby forests and has mobilized the police, armed police force and local people who have licensed guns to hunt for the animal.\\n\\nControlling this particular leopard has been a challenge for the wildlife officials in Kathmandu.\\n\\n\"We are sending a veterinary doctor to the district to understand the situation,\" Dhakal, the ecologist, said. \"There is no alternative but to kill the leopard.\"\\n\\nThe chief district administrator has granted permission for this particular leopard to be killed. Normally, it is illegal to kill wild animals.\\n\\nLeopards are common in the low mountain areas, as compared to the high Himalayas, across the country.\\n\\nWhile cases of leopards killing domestic animals are common, and there are sometimes instances of leopards killing people in Nepal, this case is \"extreme,\" Dhakal said.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['A 4-year-old boy is the latest victim of a man-eating leopard, a local police chief says',\n",
       " 'He suspects one leopard is behind the deaths of 15 people in the past 15 months',\n",
       " 'A reward has been offered to anyone who captures or kills the man-eating creature',\n",
       " 'Leopards are common in low mountain areas of Nepal but usually eat wild prey like deer']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(CNN) -- Kyle White now has two pieces of metal to wear -- one, a bracelet inscribed with the names of his six comrades killed in an ambush in Afghanistan, the other, a Medal of Honor given to him for his valor that ensured that death toll wasn\\'t higher.\\n\\nSpeaking minutes after President Barack Obama gave him the highest military honor, White insisted the two emblems are equally significant. They both represent his family on that day six years ago -- the seven others who, like him, survived as well as those who did not.\\n\\nThe former Army sergeant said Tuesday he owes it to these men, whom he calls \"my heroes,\" to live his life well, even now that he\\'s left the military, and with honor.\\n\\n\"Though I am still uncomfortable with hearing my name and the word \\'hero\\' in the same sentence, I am now ready for the challenge of proudly wearing this piece of blue fabric and carved metal with the same reverence that I wear the bracelet. And I vow to live up to the responsibility of doing so,\" White said.\\n\\nNot long before, Obama recalled White\\'s bravery and that of his colleagues.\\n\\nThe President paid tribute to those who died that fall day in Afghanistan and those who survived. They had done everything their country could ask for and more.\\n\\n\"Kyle, members of Chosen Company, you did your duty,\" Obama said. \"And now it\\'s time for America to do ours.\"\\n\\nWhite himself insisted that the Medal of Honor cannot really be an individual award, calling it \"a testament to the trust we have in each other and our leaders.\"\\n\\nStill, the President said that he deserved to be singled out. A high school freshman when the Twin Towers fell on September 11, 2001, White joined the Army and was just 20 years old and 21 months into his military service when he faced the ultimate test.\\n\\nHe aced it, and in doing so represented the best of what Obama called the \"9/11 generation (which) has proven itself to be one of America\\'s greatest.\"\\n\\n\"Today,\" the President said to a crowd that included White, his parents and many of his former comrades, \"we pay tribute to a soldier who embodies the courage of his generation.\"\\n\\nAttacked in \\'ambush alley\\'\\n\\nOn Tuesday, White dressed in full uniform. But on most other weekdays, he now wears a suit to his job as an investment analyst at a bank in Charlotte, North Carolina -- a job that he\\'s admitted to Obama, with a laugh, is less exciting than his previous job in the Army.\\n\\nThe Washington state native joined up after high school, following the lead of his father, a former Army Special Forces member. His service had, like many other members of the military, earned him a ticket to Afghanistan as his platoon\\'s radio telephone operator.\\n\\nHe was there on November 9, 2007, walking back from a meeting with elders with his unit of 14 and a squad of Afghan army soldiers.\\n\\n\"They knew not to stop, they had to keep moving,\" Obama recalled of the group walking single-file with a cliff to their right and a steep, rocky slope to their left. \"They were heading into an area known as ambush alley.\"\\n\\nIn an interview prior to the award ceremony, White told CNN how the group walked \"down this little incline and looking into the valley, (when) I hear this single shot. Then two shots, then the echo, then fully automatic gunfire.\"\\n\\nTaking so much fire, members of his patrol were separated as they tried to take cover. White was finishing off his first magazine and beginning to load another one when an rocket-propelled grenade exploded, knocking him unconscious.\\n\\nMoments after he came to, an enemy round hit a rock just inches from his head. The shrapnel and rock fragments cut his face.\\n\\nDazed, he struggled to take in what was happening. He and four others had been separated from the other soldiers, who\\'d jumped from a cliff. White administered first aid to one wounded soldier using the only cover available: a single tree. That soldier would survive.\\n\\nIt was at that point in the attack that White realized his radio wasn\\'t working.\\n\\nHe looked out and saw a member of his patrol about 30 feet away whose wounds were so bad that he could not move. White ran toward him, braving enemy fire.\\n\\nWhite was able to drag the wounded man back to the tree.\\n\\nBut the man\\'s injuries were too severe, and he died.\\n\\nRisking death, again and again\\n\\nWhite continued to risk himself to help his fellow warriors, again running from cover into enemy fire to reach the platoon leader. White told the military publication Stars and Stripes that he could see the leader\\'s helmet and assault pack, but he couldn\\'t tell whether the leader was alive. White had to see, he said.\\n\\nWhite crawled toward the man. It was too late. He was dead.\\n\\nWhite figured he would be killed. But he would do what he was trained to do. He would carry out his duty.\\n\\n\"It was never a choice,\" he explained to CNN. \"I told myself from the beginning that I was going to be killed, you know... just the amount of fire ... I\\'m not gonna make it through this.\"\\n\\nBut he kept focused. The soldier White had dragged to the tree earlier was hit again, this time in the knee, so the White wrapped his belt around the man\\'s leg, creating a tourniquet.\\n\\nThen White found a working radio on a deceased comrade and called for artillery and helicopter gunships to help.\\n\\nFinally, maybe, there could be hope. But then a friendly mortar round landed near White.\\n\\n\"I remember just red hot chunks of metal like the size of my palm just flinging by your head,\" he told Stars and Stripes.\\n\\nSuffering a concussion, White managed to hang on, waiting for helicopters to evacuate him and others with him that day. When help arrived, he told his rescuers to put the other wounded aboard first.\\n\\nA soldier, changed\\n\\nSpeaking with National Public Radio this week, White said the experience -- from the violence to the wait -- seemed like \"forever.\" And it hasn\\'t entirely gone away, all these years later.\\n\\n\"It\\'s something you still think about every day,\" White said. \"I still have these images from that day burned into my head. But it\\'s something, as time goes on, it gets easier.\"\\n\\nBut something inside him changed, he said.\\n\\n\"Even to this day, you know, I can\\'t say if it was something good or bad. ...\" he told NPR. \"And that was pretty much the reason why I decided to leave the Army.\"\\n\\nWhite first returned home and trained other paratrooopers. When it came time for White to re-enlist, he thought hard about whether doing so felt right. He decided against it because he doubted that he could devote his complete heart and mind to it, he told NPR.\\n\\nIt was unacceptable to him to continue in the service and then, perhaps, be deployed to Afghanistan. Service members deserve a leader who is all in, he explained.\\n\\nObama called him on February 10 to tell him he\\'d be given the Medal of Honor. He\\'s the 10th recipient of that award for his actions in Afghanistan, and the seventh surviving recipient. Four service members received the Medal of Honor -- all posthumously -- for actions in the war in Iraq, according to the Congressional Medal of Honor Society.\\n\\nIn a brief statement to reporters after Tuesday\\'s ceremony, White called the Medal of Honor \"a symbol of the responsibility all soldiers knowingly face when they depart for distant lands in defense of the nation, a responsibility that locks us all in the bonds of brotherhood.\"\\n\\nAs such, White couldn\\'t help but think about his brothers in arms.\\n\\n\"Without the team,\" he said, \"there could be no Medal of Honor. That is why I wear this medal for my team.\"\\n\\nRead the transcript of the White House ceremony\\n\\n24 minority veterans receive long overdue Medal of Honor\\n\\nSee Kyle White\\'s Army profile\\n\\nCNN\\'s Barbara Starr contributed to this report.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['NEW: Kyle White: \"Without this team, there would be no Medal of Honor\"',\n",
       " 'NEW: He vows to \"live up to the responsibility\" of having the top military award',\n",
       " 'NEW: Obama calls White \"a soldier who embodies the courage of his generation\"',\n",
       " 'The Army vet, then 20, braved enemy fire to save his wounded comrades in Afghanistan']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(CNN) -- The 54 men and 14 boys rescued after being found chained this week at an Islamic religious school in Pakistan have been reunited with their families or placed in shelters, authorities said.\\n\\nThe group was discovered in an underground room with heavy chains linking them together.\\n\\nThe school, Al-Arabiya Aloom Jamia Masjid Zikirya, which also was a drug rehab clinic, is in Sohrab Goth, a suburb of Gadap in Karachi.\\n\\nAll 14 boys were returned to their families, senior police official Ahsanullah Marwat told CNN.\\n\\nOf the adults, 47 had been released to their families, and seven were handed over to a shelter for the homeless, he said.\\n\\nThree people who worked at the facility were arrested, but the four men who ran the place were still at large, Marwat said.\\n\\nOfficials said the facility was part madrassa and part drug-rehab facility, and the captives were chained at night apparently to prevent their escape.\\n\\n\"The operation was successful, and we plan on continuing our work to ensure that places like this are shut down,\" Marwat said.\\n\\nMany of the captives told police their families sent them there because they were recovering drug addicts. During the day, they worked and did religious studies.\\n\\nBut the future of the rescued children was unclear.\\n\\nOne woman told a local television station that she was willing to pay the police to keep her troublesome child. She said she would rather have the facility remain open, regardless of how it treated the children.\\n\\nMany others, however, said they were in shock and disbelief over the allegations.\\n\\nOne man complained he was deep in debt after paying the school a large amount of money to board his son.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Captive boys and men were rescued from an Islamic religious school in Pakistan',\n",
       " 'They were reunited with their families this week',\n",
       " 'The facility was a school and drug rehab clinic',\n",
       " \"Authorities say they're searching for the owners; three others arrested at the facility\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews.dropna()\n",
    "\n",
    "reviews = reviews.reset_index(drop=True)\n",
    "\n",
    "display(reviews.head())\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    print(\"Review #\",i+1)\n",
    "\n",
    "    display(reviews.story[i])\n",
    "\n",
    "    display(reviews.highlights[i])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\n",
    "\"ain't\": \"am not\",\n",
    "\n",
    "\"aren't\": \"are not\",\n",
    "\n",
    "\"can't\": \"cannot\",\n",
    "\n",
    "\"can't've\": \"cannot have\",\n",
    "\n",
    "\"'cause\": \"because\",\n",
    "\n",
    "\"could've\": \"could have\",\n",
    "\n",
    "\"couldn't\": \"could not\",\n",
    "\n",
    "\"couldn't've\": \"could not have\",\n",
    "\n",
    "\"didn't\": \"did not\",\n",
    "\n",
    "\"doesn't\": \"does not\",\n",
    "\n",
    "\"don't\": \"do not\",\n",
    "\n",
    "\"hadn't\": \"had not\",\n",
    "\n",
    "\"hadn't've\": \"had not have\",\n",
    "\n",
    "\"hasn't\": \"has not\",\n",
    "\n",
    "\"haven't\": \"have not\",\n",
    "\n",
    "\"he'd\": \"he would\",\n",
    "\n",
    "\"he'd've\": \"he would have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords=True, is_list=False):\n",
    "\n",
    "    # Convert words to lower case\n",
    "    if not is_list:\n",
    "        \n",
    "        text = text.lower()\n",
    "\n",
    "        text = text.split()\n",
    "\n",
    "        new_text = []\n",
    "\n",
    "        for word in text:\n",
    "\n",
    "            if word in contractions:\n",
    "\n",
    "                new_text.append(contractions[word])\n",
    "\n",
    "        else:\n",
    "\n",
    "            new_text.append(word)\n",
    "\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        text = re.sub(r'\\<a href', ' ', text)\n",
    "\n",
    "        text = re.sub(r'&amp;', '', text)\n",
    "\n",
    "        text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "\n",
    "        text = re.sub(r'<br />', ' ', text)\n",
    "\n",
    "        text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "        if remove_stopwords:\n",
    "\n",
    "            text = text.split()\n",
    "\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "            text = [w for w in text if not w in stops]\n",
    "\n",
    "            text = \" \".join(text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        summ = []\n",
    "        \n",
    "        for highlight in text:\n",
    "            \n",
    "            highlight = highlight.lower()\n",
    "\n",
    "            highlight = highlight.split()\n",
    "\n",
    "            new_text = []\n",
    "\n",
    "            for word in highlight:\n",
    "\n",
    "                if word in contractions:\n",
    "\n",
    "                    new_text.append(contractions[word])\n",
    "\n",
    "            else:\n",
    "\n",
    "                new_text.append(word)\n",
    "\n",
    "            highlight = \" \".join(new_text)\n",
    "\n",
    "            highlight = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', highlight, flags=re.MULTILINE)\n",
    "\n",
    "            highlight = re.sub(r'\\<a href', ' ', highlight)\n",
    "\n",
    "            highlight = re.sub(r'&amp;', '', highlight)\n",
    "\n",
    "            highlight = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', highlight)\n",
    "\n",
    "            highlight = re.sub(r'<br />', ' ', highlight)\n",
    "\n",
    "            highlight = re.sub(r'\\'', ' ', highlight)\n",
    "\n",
    "            if remove_stopwords:\n",
    "\n",
    "                highlight = highlight.split()\n",
    "\n",
    "                stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "                highlight = [w for w in highlight if not w in stops]\n",
    "\n",
    "                highlight = \" \".join(highlight)\n",
    "                \n",
    "            summ.append(highlight)\n",
    "        \n",
    "        return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\lenovo\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "# Clean the summaries and texts\n",
    "\n",
    "clean_summaries = []\n",
    "\n",
    "for summary in reviews.highlights:\n",
    "\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False, is_list=True))\n",
    "\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "\n",
    "for text in reviews.story:\n",
    "\n",
    "    clean_texts.append(clean_text(text))\n",
    "\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = list()\n",
    "\n",
    "for i, text in enumerate(clean_texts):\n",
    "\n",
    "    stories.append({'story': text, 'highlights': clean_summaries[i]})\n",
    "\n",
    "# save to file\n",
    "\n",
    "dump(stories, open('cnn_stories.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "epochs = 110\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 20\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "stories = load(open('cnn_stories.pkl', 'rb'))\n",
    "\n",
    "print('Loaded Stories %d' % len(stories))\n",
    "\n",
    "print(type(stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20\n",
      "Number of unique input tokens: 20\n",
      "Number of unique output tokens: 23\n",
      "Max sequence length for inputs: 31\n",
      "Max sequence length for outputs: 13\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "for story in stories:\n",
    "    input_text = story['story']\n",
    "    for highlight in story['highlights']:\n",
    "        target_text = highlight\n",
    "\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(n_input, n_output, n_units):\n",
    "\n",
    "    # define training encoder\n",
    "\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # define training decoder\n",
    "\n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference encoder\n",
    "\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    # define inference decoder\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs,  initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    # return all models\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/110\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 1.9468 - val_loss: 1.4966\n",
      "Epoch 2/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9220 - val_loss: 1.4819\n",
      "Epoch 3/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8920 - val_loss: 1.4043\n",
      "Epoch 4/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7481 - val_loss: 1.8085\n",
      "Epoch 5/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.1002 - val_loss: 1.4550\n",
      "Epoch 6/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7071 - val_loss: 1.5263\n",
      "Epoch 7/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6903 - val_loss: 1.5394\n",
      "Epoch 8/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.6868 - val_loss: 1.4720\n",
      "Epoch 9/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6348 - val_loss: 1.4610\n",
      "Epoch 10/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6059 - val_loss: 1.4582\n",
      "Epoch 11/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5935 - val_loss: 1.4786\n",
      "Epoch 12/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.5869 - val_loss: 1.4683\n",
      "Epoch 13/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.5836 - val_loss: 1.5065\n",
      "Epoch 14/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5894 - val_loss: 1.4817\n",
      "Epoch 15/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5846 - val_loss: 1.5112\n",
      "Epoch 16/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5784 - val_loss: 1.4877\n",
      "Epoch 17/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5624 - val_loss: 1.5102\n",
      "Epoch 18/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5528 - val_loss: 1.5054\n",
      "Epoch 19/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5465 - val_loss: 1.5257\n",
      "Epoch 20/110\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5430 - val_loss: 1.5278\n",
      "Epoch 21/110\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5435 - val_loss: 1.5350\n",
      "Epoch 22/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5399 - val_loss: 1.5375\n",
      "Epoch 23/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5356 - val_loss: 1.5397\n",
      "Epoch 24/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5194 - val_loss: 1.5365\n",
      "Epoch 25/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5142 - val_loss: 1.5970\n",
      "Epoch 26/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5325 - val_loss: 1.5374\n",
      "Epoch 27/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5489 - val_loss: 1.5772\n",
      "Epoch 28/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5104 - val_loss: 1.5630\n",
      "Epoch 29/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5217 - val_loss: 1.5654\n",
      "Epoch 30/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4693 - val_loss: 1.5762\n",
      "Epoch 31/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4520 - val_loss: 1.6381\n",
      "Epoch 32/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4943 - val_loss: 1.5342\n",
      "Epoch 33/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6071 - val_loss: 1.5586\n",
      "Epoch 34/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4734 - val_loss: 1.5899\n",
      "Epoch 35/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4654 - val_loss: 1.5820\n",
      "Epoch 36/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4440 - val_loss: 1.5914\n",
      "Epoch 37/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4358 - val_loss: 1.6238\n",
      "Epoch 38/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4214 - val_loss: 1.5831\n",
      "Epoch 39/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4475 - val_loss: 1.6856\n",
      "Epoch 40/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4894 - val_loss: 1.5775\n",
      "Epoch 41/110\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4902 - val_loss: 1.6107\n",
      "Epoch 42/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4277 - val_loss: 1.6422\n",
      "Epoch 43/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5035 - val_loss: 1.5791\n",
      "Epoch 44/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4073 - val_loss: 1.6103\n",
      "Epoch 45/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3694 - val_loss: 1.6180\n",
      "Epoch 46/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3434 - val_loss: 1.6663\n",
      "Epoch 47/110\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3463 - val_loss: 1.6722\n",
      "Epoch 48/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4080 - val_loss: 1.6538\n",
      "Epoch 49/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4669 - val_loss: 1.6732\n",
      "Epoch 50/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3954 - val_loss: 1.6720\n",
      "Epoch 51/110\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3849 - val_loss: 1.6334\n",
      "Epoch 52/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3378 - val_loss: 1.6574\n",
      "Epoch 53/110\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.3272 - val_loss: 1.6957\n",
      "Epoch 54/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.3611 - val_loss: 1.6468\n",
      "Epoch 55/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3799 - val_loss: 1.7150\n",
      "Epoch 56/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3422 - val_loss: 1.6822\n",
      "Epoch 57/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3645 - val_loss: 1.7222\n",
      "Epoch 58/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3691 - val_loss: 1.6742\n",
      "Epoch 59/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2670 - val_loss: 1.6067\n",
      "Epoch 60/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3978 - val_loss: 1.6574\n",
      "Epoch 61/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2592 - val_loss: 1.7942\n",
      "Epoch 62/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2494 - val_loss: 1.7079\n",
      "Epoch 63/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.2819 - val_loss: 1.7698\n",
      "Epoch 64/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3609 - val_loss: 1.7781\n",
      "Epoch 65/110\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3157 - val_loss: 1.7031\n",
      "Epoch 66/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2032 - val_loss: 1.7084\n",
      "Epoch 67/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2058 - val_loss: 1.8057\n",
      "Epoch 68/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2972 - val_loss: 1.7207\n",
      "Epoch 69/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2329 - val_loss: 1.7879\n",
      "Epoch 70/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1773 - val_loss: 1.7799\n",
      "Epoch 71/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1967 - val_loss: 1.8156\n",
      "Epoch 72/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2070 - val_loss: 1.8197\n",
      "Epoch 73/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1828 - val_loss: 1.7183\n",
      "Epoch 74/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2868 - val_loss: 1.8483\n",
      "Epoch 75/110\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4184 - val_loss: 1.7888\n",
      "Epoch 76/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1525 - val_loss: 1.7577\n",
      "Epoch 77/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1104 - val_loss: 1.7955\n",
      "Epoch 78/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1197 - val_loss: 1.8096\n",
      "Epoch 79/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1357 - val_loss: 1.7988\n",
      "Epoch 80/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1289 - val_loss: 1.7969\n",
      "Epoch 81/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0771 - val_loss: 1.8527\n",
      "Epoch 82/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0274 - val_loss: 1.8613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0122 - val_loss: 1.9005\n",
      "Epoch 84/110\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0210 - val_loss: 1.8742\n",
      "Epoch 85/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0427 - val_loss: 1.9183\n",
      "Epoch 86/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0724 - val_loss: 1.8651\n",
      "Epoch 87/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2439 - val_loss: 1.8788\n",
      "Epoch 88/110\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1781 - val_loss: 1.8363\n",
      "Epoch 89/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4134 - val_loss: 1.8686\n",
      "Epoch 90/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0121 - val_loss: 1.8493\n",
      "Epoch 91/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9472 - val_loss: 1.8936\n",
      "Epoch 92/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9321 - val_loss: 1.9388\n",
      "Epoch 93/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9777 - val_loss: 1.9624\n",
      "Epoch 94/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0099 - val_loss: 1.9567\n",
      "Epoch 95/110\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9548 - val_loss: 1.9016\n",
      "Epoch 96/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9509 - val_loss: 2.0176\n",
      "Epoch 97/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9751 - val_loss: 1.8688\n",
      "Epoch 98/110\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9932 - val_loss: 2.0357\n",
      "Epoch 99/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9168 - val_loss: 1.9591\n",
      "Epoch 100/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9306 - val_loss: 2.0470\n",
      "Epoch 101/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9418 - val_loss: 1.9743\n",
      "Epoch 102/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9411 - val_loss: 1.8985\n",
      "Epoch 103/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9126 - val_loss: 2.0245\n",
      "Epoch 104/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9322 - val_loss: 1.9072\n",
      "Epoch 105/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8483 - val_loss: 2.0800\n",
      "Epoch 106/110\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8467 - val_loss: 1.9624\n",
      "Epoch 107/110\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.8515 - val_loss: 2.1249\n",
      "Epoch 108/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.8919 - val_loss: 2.0129\n",
      "Epoch 109/110\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.0007 - val_loss: 2.1109\n",
      "Epoch 110/110\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9463 - val_loss: 1.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo pc\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:872: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "\t# encode\n",
    "\tstate = infenc.predict(source)\n",
    "\t# start of sequence input\n",
    "\ttarget_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "\t# collect predictions\n",
    "\toutput = list()\n",
    "\tfor t in range(n_steps):\n",
    "\t\t# predict next char\n",
    "\t\tyhat, h, c = infdec.predict([target_seq] + state)\n",
    "\t\t# store prediction\n",
    "\t\toutput.append(yhat[0,0,:])\n",
    "\t\t# update state\n",
    "\t\tstate = [h, c]\n",
    "\t\t# update target sequence\n",
    "\t\ttarget_seq = yhat\n",
    "\treturn array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, infenc, infdec = define_models(51, 51, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-fcbbe6ee9525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfenc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'story'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m51\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-0ab9b14efeef>\u001b[0m in \u001b[0;36mpredict_sequence\u001b[1;34m(infenc, infdec, source, n_steps, cardinality)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfenc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfenc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;31m# start of sequence input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtarget_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                              'argument.')\n\u001b[0;32m   1146\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "target = predict_sequence(infenc, infdec, stories[0]['story'], 3, 51)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
